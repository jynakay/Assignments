---
title: "Homework 8"
author: "Jasmine Nakayama"
date: "April 12, 2018"
output: html_document
---

Link to repository: (https://github.com/jynakay/Assignments)[https://github.com/jynakay/Assignments]. 

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(class)
library(rpart)
library(NHANES)
library(RColorBrewer)
library(plot3D)
library(parallel)
library(randomForestSRC)
library(ggRandomForests)
library(mosaic)
library(dplyr)
```

####Problem 1

Create the NHANES dataset again, just like we did in class, only using sleep trouble (variable name = SleepTrouble) as the dependent variable, instead of SleepTrouble. 

What is the marginal distribution of sleep trouble?

```{r Q1a}
#create dataset
people <- NHANES %>% dplyr::select(Age, Gender,SleepTrouble, BMI, HHIncome, PhysActive) 
glimpse(people)

#marginal distribution of sleep trouble
tally(~ SleepTrouble, data = people, format = "percent")
```

Recall from our prior work, the packages work better if the dataset is a dataframe, and the variables are numeric.

```{r Q1b}
# Convert to dataframe
people <- as.data.frame(people)
class(people)
glimpse(people)

#convert variables to numeric
people$Age <- as.numeric(people$Age)
people$Gender <- as.numeric(people$Gender)
people$SleepTrouble <- as.numeric(people$SleepTrouble)
people$BMI <- as.numeric(people$BMI)
people$HHIncome <- as.numeric(people$HHIncome)
people$PhysActive <- as.numeric(people$PhysActive)

people <- na.omit(people)

glimpse(people)
```

####Problem 2

Apply the k-nearest neighbor procedure to predict SleepTrouble from the other covariates. Use k = 1, 3, 5, and 20.

```{r Q2}
#Apply k-nearest neighbor approach to predict SleepTrouble for k = 1, 3, 5, 20
knn.1 <- knn(train = people, test = people, cl = people$SleepTrouble, k = 1)
knn.3 <- knn(train = people, test = people, cl = people$SleepTrouble, k = 3)
knn.5 <- knn(train = people, test = people, cl = people$SleepTrouble, k = 5)
knn.20 <- knn(train = people, test = people, cl = people$SleepTrouble, k = 20)
```


####Problem 3

Now let's see how well these classifiers work overall.

```{r Q3}

# Calculate the percent predicted correctly

100*sum(people$SleepTrouble == knn.1)/length(knn.1)
100*sum(people$SleepTrouble == knn.3)/length(knn.3)
100*sum(people$SleepTrouble == knn.5)/length(knn.5)
100*sum(people$SleepTrouble == knn.20)/length(knn.20)

```

####Problem 4

What about success overall?

```{r Q4}

# Another way to look at success rate against increasing k

table(knn.1, people$SleepTrouble)
table(knn.3, people$SleepTrouble)
table(knn.5, people$SleepTrouble)
table(knn.20, people$SleepTrouble)

```


