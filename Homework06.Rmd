---
title: "Homework 6"
author: "Jasmine Nakayama"
date: "April 6, 2018"
output:
  html_document: default
  pdf_document: default
---

Link to repository: (https://github.com/jynakay/Assignments)[https://github.com/jynakay/Assignments] 

```{r setup, message=FALSE, warning=FALSE}
# load libraries and dataset
library(tidyverse)
library(haven)
library(car)
library(ROCR)
```

```{r load dataset}
helpdata <- haven::read_spss("helpmkh.sav")

# choose variable
h1 <- helpdata %>%
  select(age, female, pss_fr, homeless, 
         pcs, mcs, cesd)

# add dichotomous variable to indicate depression for people with CESD scores >= 16
h1 <- h1 %>%
  mutate(cesd_gte16 = cesd >= 16)

# change cesd_gte16 LOGIC variable type to numeric coded 1=TRUE and 0=FALSE
h1$cesd_gte16 <- as.numeric(h1$cesd_gte16)

# check final data subset h1
summary(h1)
```

###1. [Model 1] Run a simple linear regression (`lm()`) for `cesd` using the `mcs` variable, which is the mental component quality of life score from the SF36.

```{r Q1}
slr<-lm(cesd~mcs, data=h1)
slr
```

###2. Write the equation of the final fitted model (i.e. what is the intercept and the slope)? Write a sentence describing the model results (interpret the intercept and slope). 
`cesd=53.9022-0.6647*mcs`

For every 1 point increase in MCS score, the CEDS score decreases by 0.6647. Generally, better mental health is associated with lower depression score. Those with an MCS score of 0 will have a CESD of 53.9022.

###3. How much variability in the `cesd` does the `mcs` explain? (what is the R<sup>2</sup>?) Write a sentence describing how well the `mcs` does in predicting the `cesd`.

```{r Q3, include=FALSE}
summary(slr)
```
The adjusted R<sup>2</sup> is 0.4638, which indicates that `cesd` accounts for 46.38% of the variability in `mcs`, which is fairly good for a simple linear regression model.

###4. [Model 2] Run a second linear regression model (`lm()`) for the `cesd` putting in all of the other variables: 
   
```{r Q4}
mlr<-lm(cesd~age +female +pss_fr +homeless +pcs +mcs, data=h1)
summary(mlr)
```

###5. Which variables are significant in the model? Write a sentence or two describing the impact of these variables for predicting depression scores (HINT: interpret the coefficient terms).

When adjusting for the other variables in the model, the following variables are significant in the model: `female`, `pss_fr`, `pcs`, and `mcs`. When adjusting for the other variables, a 1 unit increase in `female` results in a 2.35028 increase in `cesd`, and a 1 unit increase in `pss_fr`, `pcs`, or `mcs` results in a 0.25569, 0.23639, or 0.62093 decrease in `cesd` respectively.

###6. generate the diagnostic plots for this model with these 6 predictors (e.g. get the residual plot by variables, the added-variable plots, the Q-Q plot, diagnostic plots). Also run the VIFs to check for multicollinearity issues.

```{r Q6}
residualPlots(mlr)
avPlots(mlr, id.n=2, id.cex=0.7)
qqPlot(mlr)
outlierTest(mlr)
influenceIndexPlot(mlr)
influencePlot(mlr)
vif(mlr)
```

###7. [Model 3] Repeat Model 1 above, except this time run a logistic regression (`glm()`) to predict CESD scores => 16 (using the `cesd_gte16` as the outcome) as a function of `mcs` scores. Show a summary of the final fitted model and explain the coefficients. 

```{r Q7}
glm <- glm(cesd_gte16 ~ mcs, 
  family=binomial(logit), data=h1)
summary(glm)
exp(coef(glm))  # Exponentiated coefficients ("odds ratios")
```

The odds of CESD score greater than or equal to 16 is 0.8423518 higher for each increase in MCS.

###8. Use the `predict()` function like we did in class to predict CESD => 16 and compare it back to the original data. For now, use a cutoff probability of 0.5 - if the probability is > 0.5 consider this to be true and false otherwise. 
    + How well did the model correctly predict CESD scores => 16 (indicating depression)? (make the "confusion matrix" and look at the true positives and true negatives versus the false positives and false negatives).
  
```{r Q8}
glm.predict <- predict(glm, newdata=h1,
                      type="response")
table(h1$cesd_gte16, glm.predict > 0.5)
t1 <- table(glm.predict > 0.5, h1$cesd_gte16)
t1
```
The model was able to predict 395 of the 419 true cases CESD scores =>16.

###9. Make an ROC curve plot and compute the AUC and explain if this is a good model for predicting depression or not.

```{r Q9}
p <- predict(glm, newdata=h1, 
             type="response")
pr <- prediction(p, as.numeric(h1$cesd_gte16))
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
abline(a=0, b=1, col="red")

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
```

AUC of 0.922 is great, so this is a good model to predict depression.

###10. Make a plot showing the probability curve - put the `mcs` values on the X-axis and the probability of depression on the Y-axis. Based on this plot, do you think the `mcs` is a good predictor of depression?

```{r Q10}

plot(h1$mcs, glm.predict)
```

MCS less than 30 seems to indicate depression. With MCS scores greater than 30, higher scores indicate less depression.